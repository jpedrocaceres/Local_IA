# Guia R√°pido: Sele√ß√£o de Modelos

## üöÄ In√≠cio R√°pido em 3 Passos

### 1Ô∏è‚É£ Escolher o Modelo

```bash
python select_model.py
```

### 2Ô∏è‚É£ Configurar o Modelo

#### Op√ß√£o A: Llama 3.1 (Chat Geral)
```bash
ollama pull llama3.1:8b
```

#### Op√ß√£o B: TRM (Racioc√≠nio)
```bash
python setup_trm.py
```

### 3Ô∏è‚É£ Iniciar o Servidor

```bash
python main.py
```

Acesse: http://localhost:8000

---

## ü§î Qual Modelo Escolher?

### Use **Llama 3.1** para:
- ‚úÖ Conversa√ß√£o geral
- ‚úÖ Responder perguntas sobre qualquer assunto
- ‚úÖ Gerar textos, c√≥digos, artigos
- ‚úÖ Seguir instru√ß√µes complexas
- ‚úÖ Contexto e nuances de linguagem

**Requer:** 8-16GB VRAM

### Use **TRM** para:
- ‚úÖ Puzzles l√≥gicos (Sudoku, Mazes)
- ‚úÖ Reconhecimento de padr√µes (ARC-AGI)
- ‚úÖ Problemas de racioc√≠nio
- ‚úÖ Tarefas que precisam de refinamento iterativo
- ‚úÖ Baixo uso de mem√≥ria GPU

**Requer:** 2-4GB VRAM

---

## üìä Compara√ß√£o R√°pida

| Caracter√≠stica | Llama 3.1 | TRM |
|----------------|-----------|-----|
| Tamanho | 16GB | 28MB |
| Setup | F√°cil | M√©dio |
| Chat Geral | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê |
| Racioc√≠nio | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê |
| VRAM | 8-16GB | 2-4GB |

---

## üîÑ Trocar de Modelo

1. Parar servidor: `Ctrl+C`
2. Selecionar: `python select_model.py`
3. Reiniciar: `python main.py`

---

## üìö Mais Informa√ß√µes

- **Llama 3.1**: [README.md](README.md)
- **TRM**: [TRM_GUIDE.md](TRM_GUIDE.md)
- **Problemas**: [TROUBLESHOOTING.md](TROUBLESHOOTING.md)
